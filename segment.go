package lsvd

import (
	"bufio"
	"bytes"
	"context"
	"fmt"
	"io"
	"os"
	"time"

	"github.com/lab47/lsvd/logger"
	"github.com/lab47/lsvd/pkg/entropy"
	"github.com/pierrec/lz4/v4"
	"github.com/pkg/errors"
)

type SegmentCreator struct {
	log logger.Logger

	builder SegmentBuilder

	volName string

	buf []byte

	em *ExtentMap
}

type SegmentBuilder struct {
	cnt int

	emptyBlocks   int
	totalBlocks   int
	singleBEs     int
	inputBytes    int64
	storageBytes  int64
	storageRatio  float64
	compRateHisto [10]int

	buf    []byte
	header bytes.Buffer
	body   bytes.Buffer

	offset  uint64
	extents []ExtentHeader

	comp    lz4.Compressor
	useZstd bool

	entropy entropy.Estimator

	path      string
	logF      *os.File
	logW      *bufio.Writer
	curOffset int64

	em *ExtentMap
}

var histogramBands = []float64{1, 2, 3, 5, 10, 20, 50, 100, 200, 1000}

func NewSegmentCreator(log logger.Logger, vol, path string) (*SegmentCreator, error) {
	oc := &SegmentCreator{
		log:     log,
		volName: vol,
		em:      NewExtentMap(),
	}

	oc.builder.em = oc.em

	err := oc.builder.OpenWrite(path, log)
	if err != nil {
		return nil, err
	}

	return oc, nil
}

func (o *SegmentCreator) UseZstd() {
	o.builder.useZstd = true
}

func (o *SegmentBuilder) addToHistogram(val float64) {
	for i, v := range histogramBands {
		if v >= val {
			o.compRateHisto[i]++
			return
		}
	}
}

func (o *SegmentBuilder) Sync() error {
	if o.logW != nil {
		o.logW.Flush()
	}

	if o.logF != nil {
		return o.logF.Sync()
	}

	return nil
}

func (o *SegmentBuilder) OpenWrite(path string, log logger.Logger) error {
	f, err := os.OpenFile(path, os.O_CREATE|os.O_RDWR, 0644)
	if err != nil {
		return err
	}

	err = o.readLog(f, log)
	if err != nil {
		return errors.Wrapf(err, "error reading segment log")
	}

	o.logF = f
	o.logW = bufio.NewWriter(f)

	return nil
}

func (o *SegmentCreator) TotalBlocks() int {
	return o.builder.totalBlocks
}

func (o *SegmentCreator) ZeroBlocks(rng Extent) error {
	// The empty size will signal that it's empty blocks.
	_, err := o.em.Update(o.log, ExtentLocation{
		ExtentHeader: ExtentHeader{
			Extent: rng,
		},
	})
	if err != nil {
		return err
	}

	return o.builder.ZeroBlocks(rng)
}

func (o *SegmentBuilder) ZeroBlocks(rng Extent) error {
	o.cnt++

	o.extents = append(o.extents, ExtentHeader{
		Extent: rng,
	})

	return nil
}

func (o *SegmentCreator) EmptyP() bool {
	return o.builder.cnt == 0
}

func (o *SegmentBuilder) ShouldFlush(sizeThreshold int) bool {
	return o.BodySize() >= sizeThreshold
}

func (o *SegmentBuilder) BodySize() int {
	return o.body.Len()
}

func (o *SegmentCreator) ShouldFlush(sizeThreshold int) bool {
	return o.BodySize() >= sizeThreshold
}

func (o *SegmentCreator) BodySize() int {
	return int(o.builder.offset)
}

func (o *SegmentCreator) Entries() int {
	return o.builder.cnt
}

func (o *SegmentCreator) EmptyBlocks() int {
	return o.builder.emptyBlocks
}

func (o *SegmentCreator) InputBytes() int64 {
	return o.builder.inputBytes
}

func (o *SegmentCreator) StorageBytes() int64 {
	return o.builder.storageBytes
}

func (o *SegmentCreator) CompressionRate() float64 {
	return float64(o.builder.inputBytes) / float64(o.builder.storageBytes)
}

func (o *SegmentCreator) StorageRatio() float64 {
	return float64(o.builder.storageBytes) / float64(o.builder.inputBytes)
}

func (o *SegmentCreator) AvgStorageRatio() float64 {
	return o.builder.storageRatio / float64(o.builder.cnt)
}

func (o *SegmentCreator) CompressionRateHistogram() []int {
	return o.builder.compRateHisto[:]
}

// writeLog writes the header and the data to the log so that we can
// recover the write with readLog if need be.
func (o *SegmentBuilder) writeLog(
	eh ExtentHeader,
	data []byte,
) (int, int, error) {
	dw := o.logW

	sz, err := eh.Write(dw)
	if err != nil {
		return 0, 0, err
	}

	n, err := dw.Write(data)
	if err != nil || n != len(data) {
		if err != nil {
			return 0, 0, err
		}

		return 0, 0, fmt.Errorf("short write to log: %d != %d", n, len(data))
	}

	return sz, sz + n, dw.Flush()
}

// readLog is used to restore the state of the SegmentCreator from the
// log written to data.
func (o *SegmentBuilder) readLog(f *os.File, log logger.Logger) error {
	log.Debug("rebuilding memory from log", "path", f.Name())

	br := bufio.NewReader(f)

	for {
		var eh ExtentHeader

		hdrLen, err := eh.Read(br)
		if err != nil {
			if errors.Is(err, io.EOF) {
				break
			}

			log.Error("observed error reading extent header", "error", err)
			return err
		}

		log.Debug("read extent header", "extent", eh.Extent, "flags", eh.Flags(), "raw-size", eh.RawSize)

		o.totalBlocks += int(eh.Blocks)

		o.cnt++

		if eh.Size > 0 {
			n, err := br.Discard(int(eh.Size))
			if err != nil {
				return errors.Wrapf(err, "error copying body, expecting %d, got %d", eh.Size, n)
			}
			if n != int(eh.Size) {
				return fmt.Errorf("short copy: %d != %d", n, eh.Size)
			}

			if eh.RawSize > 0 {
				o.storageRatio += float64(eh.Size) / float64(eh.RawSize)
			} else {
				o.storageRatio += 1
			}

			// Update offset to match where it is in body
			eh.Offset = uint32(o.offset) + uint32(hdrLen)
			log.Trace("log rebuild offset", "extent", eh.Extent, "offset", eh.Offset)
		}

		o.extents = append(o.extents, eh)

		_, err = o.em.Update(log, ExtentLocation{
			ExtentHeader: eh,
		})
		if err != nil {
			return err
		}

		o.offset += (uint64(eh.Size) + uint64(hdrLen))
	}

	return nil
}

// FillExtent attempts to fill as much of +data+ as possible, returning
// a list of Extents that was unable to fill. That later list is then
// feed to the system that reads data from segments.
func (o *SegmentCreator) FillExtent(data RangeDataView) ([]Extent, error) {
	startFill := time.Now()

	rng := data.Extent

	ranges, err := o.em.Resolve(o.log, rng)
	if err != nil {
		return nil, err
	}

	var ret []Extent

	var compTime time.Duration
	for _, srcRng := range ranges {
		subDest, ok := data.SubRange(srcRng.Live)
		if !ok {
			o.log.Error("error calculating subrange")
			return nil, fmt.Errorf("error calculating subrange")
		}

		o.log.Trace("calculating relevant ranges",
			"data", rng,
			"src", srcRng.Live,
			"dest", subDest.Extent,
			"offset", srcRng.Offset,
		)

		ret = append(ret, subDest.Extent)

		// It's a empty range
		if srcRng.Size == 0 {
			continue
		}

		o.log.Trace("reading partial from write cache", "rng", srcRng.Live, "dest", subDest.Extent, "flags", srcRng.Flags())

		var srcData []byte

		switch srcRng.Flags() {
		case Uncompressed:
			if len(o.buf) < int(srcRng.Size) {
				o.buf = make([]byte, srcRng.Size)
			}

			srcData = o.buf[:srcRng.Size]

			offset := srcRng.Offset // + (uint32(subDest.LBA-srcRng.LBA) * BlockSize)
			o.log.Trace("reading uncompressed from write log", "src", srcRng.Live, "dest", subDest.Extent, "byte-offset", offset)
			n, err := o.builder.logF.ReadAt(srcData, int64(offset))
			if err != nil {
				return nil, err
			}

			if n != len(srcData) {
				return nil, fmt.Errorf("reading from write log returned wrong number of bytes (%d, %d)", n, subDest.ByteSize())
			}
		case Compressed:
			s := time.Now()
			origSize := srcRng.Size // Size is the "on-disk" size, ie the compressed size

			if len(o.buf) < int(origSize) {
				o.buf = make([]byte, origSize)
			}

			srcData = o.buf[:origSize]

			n, err := o.builder.logF.ReadAt(srcData, int64(srcRng.Offset))
			if err != nil {
				o.log.Trace("file size on read failure", "size", o.builder.offset)
				return nil, errors.Wrapf(err, "reading extent at %d:%d (%d, %d)",
					srcRng.Offset, srcRng.Size, len(srcData), srcRng.RawSize)
			}

			if n != len(srcData) {
				return nil, fmt.Errorf("reading from write log returned wrong number of bytes 2 (%d, %d)", n, len(srcData))
			}

			o.log.Debug("compressed range", "offset", srcRng.Offset)

			o.log.Debug("original size of compressed extent", "len", srcRng.RawSize, "comp-size", srcRng.Size)

			uncompData := buffers.Get(int(srcRng.RawSize))
			defer buffers.Return(uncompData)

			n, err = lz4.UncompressBlock(srcData, uncompData)
			if err != nil {
				return nil, fmt.Errorf("fill-extent: error uncompressing (src=%d, dest=%d): %w", len(srcData), len(uncompData), err)
			}

			if n > int(srcRng.RawSize) {
				o.log.Warn("unusual long write detected", "expected", origSize, "actual", n, "buf-len", len(o.buf))
			} else if n < int(srcRng.RawSize) {
				return nil, fmt.Errorf("didn't fill destination (%d != %d)", n, origSize)
			}

			srcData = uncompData

			compTime += time.Since(s)
		case Empty:
			// handled above, shouldn't be here.
			return nil, fmt.Errorf("invalid flag 2, should have size == 0, did not")
		default:
			return nil, fmt.Errorf("invalid flag %d", srcRng.Flags())
		}

		src := MapRangeData(srcRng.Extent, srcData)

		subSrc, ok := src.SubRange(subDest.Extent)
		if !ok {
			o.log.Error("error calculating src subrange")
			return nil, fmt.Errorf("error calculating src subrange")
		}

		o.log.Debug("mapping src range", "rng", subSrc.Extent)

		n := subDest.Copy(subSrc)

		o.log.Debug("copied range", "bytes", n, "blocks", n/BlockSize)
	}

	e := time.Since(startFill)

	readProcessing.Add(e.Seconds())
	compressionOverhead.Add(compTime.Seconds())

	return ret, nil
}

func (o *SegmentCreator) WriteExtent(ext RangeData) error {
	_, eh, err := o.builder.WriteExtent(o.log, ext.View())
	if err != nil {
		return err
	}

	if o.em == nil {
		o.em = NewExtentMap()
	}

	_, err = o.em.Update(o.log, ExtentLocation{
		ExtentHeader: eh,
	})

	if err != nil {
		return err
	}

	return nil
}

type SegmentStats struct {
	Blocks     uint64
	TotalBytes uint64
	DataOffset uint32
}

func (o *SegmentCreator) Flush(ctx context.Context,
	sa SegmentAccess, seg SegmentId,
) ([]ExtentLocation, *SegmentStats, error) {
	locs, stats, err := o.builder.Flush(ctx, o.log, sa, seg, o.volName)
	if err != nil {
		return locs, stats, err
	}

	return locs, stats, nil
}

func (o *SegmentCreator) Close() error {
	return o.builder.Close(o.log)
}

func (o *SegmentBuilder) Close(log logger.Logger) error {
	if o.logF != nil {
		o.logF.Close()

		log.Debug("removing log file", "name", o.logF.Name())
		err := os.Remove(o.logF.Name())
		if err != nil {
			log.Error("error removing log file", "error", err)
		}
	}

	return nil
}

const entropyLimit = 7.0

func (o *SegmentBuilder) WriteExtent(log logger.Logger, ext RangeDataView) ([]byte, ExtentHeader, error) {
	extBytes := ext.ByteSize()
	if o.buf == nil {
		o.buf = make([]byte, extBytes*2)
	}

	o.totalBlocks += int(ext.Blocks)

	var data []byte

	eh := ExtentHeader{
		Extent: ext.Extent,
	}

	o.cnt++

	if ext.EmptyP() {
		o.emptyBlocks += int(ext.Blocks)
	} else {
		if ext.Blocks == 1 {
			o.singleBEs++
		}

		input := ext.ReadData()
		o.inputBytes += int64(len(input))

		if o.entropy == nil {
			o.entropy = entropy.NewEstimator()
		}

		o.entropy.Reset()
		o.entropy.Write(ext.ReadData())

		var (
			useCompression bool
			compressedSize int
			err            error
		)

		if o.entropy.Value() <= entropyLimit {
			bound := lz4.CompressBlockBound(extBytes)

			if len(o.buf) < bound {
				o.buf = make([]byte, bound)
			}

			compressedSize, err = o.comp.CompressBlock(ext.ReadData(), o.buf)
			if err != nil {
				return nil, eh, err
			}

			// Only keep compression greater than 1.5x
			if compressedSize > 0 && ((compressedSize*3)/2) < extBytes {
				useCompression = true
			}
		}

		if useCompression {
			eh.RawSize = uint32(extBytes)
			eh.Size = uint32(compressedSize)

			data = o.buf[:compressedSize]

			o.addToHistogram(float64(len(input)) / float64(len(data)))
		} else {
			eh.Size = uint32(extBytes)

			data = ext.ReadData()

			o.addToHistogram(1)
		}

		o.storageBytes += int64(len(data))
		o.storageRatio += (float64(len(data)) / float64(len(input)))
	}

	hdr, n, err := o.writeLog(eh, data)
	if err != nil {
		return nil, eh, err
	}

	eh.Offset = uint32(o.offset) + uint32(hdr)

	o.offset += uint64(n)

	log.Debug("wrote range",
		"offset", eh.Offset,
		"size", eh.Size,
		"raw-size", eh.RawSize,
		"blocks", eh.Blocks,
		"offset", eh.Offset,
	)
	o.extents = append(o.extents, eh)

	return data, eh, nil
}

func (o *SegmentBuilder) Flush(ctx context.Context, log logger.Logger,
	sa SegmentAccess, seg SegmentId, volName string,
) ([]ExtentLocation, *SegmentStats, error) {
	start := time.Now()
	defer func() {
		segmentTime.Observe(time.Since(start).Seconds())
	}()

	stats := &SegmentStats{}

	for _, blk := range o.extents {
		stats.Blocks += uint64(blk.Blocks)

		log.Trace("writing extent to header", "extent", blk.Extent, "offset", blk.Offset, "blocks", blk.Blocks)
		_, err := blk.Write(&o.header)
		if err != nil {
			return nil, nil, err
		}
	}

	dataBegin := uint32(o.header.Len() + 8)

	log.Debug("segment constructed",
		"header-size", o.header.Len(),
		"body-size", o.offset,
		"blocks", len(o.extents),
	)

	stats.DataOffset = dataBegin

	writtenBytes.Add(float64(o.inputBytes))
	segmentsBytes.Add(float64(o.storageBytes))

	entries := make([]ExtentLocation, len(o.extents))

	for i, eh := range o.extents {
		eh.Offset += dataBegin
		entries[i] = ExtentLocation{
			ExtentHeader: eh,
			Segment:      seg,
		}
		log.Trace("advertising extent", "extent", eh.Extent, "offset", eh.Offset, "blocks", eh.Blocks)
	}

	completedPath := o.path + ".complete"

	defer os.Remove(completedPath)

	f, err := os.Create(completedPath)
	if err != nil {
		return nil, nil, err
	}

	defer f.Close()

	err = SegmentHeader{
		ExtentCount: uint32(o.cnt),
		DataOffset:  dataBegin,
	}.Write(f)
	if err != nil {
		return nil, nil, err
	}

	n, err := io.Copy(f, bytes.NewReader(o.header.Bytes()))
	if err != nil {
		return nil, nil, err
	}

	stats.TotalBytes += uint64(n)

	_, err = o.logF.Seek(0, io.SeekStart)
	if err != nil {
		return nil, nil, err
	}

	n, err = io.Copy(f, o.logF)
	if err != nil {
		return nil, nil, err
	}

	stats.TotalBytes += uint64(n)

	f.Seek(0, io.SeekStart)

	err = sa.UploadSegment(ctx, seg, f)
	if err != nil {
		return nil, nil, err
	}

	err = sa.AppendToSegments(ctx, volName, seg)
	if err != nil {
		return nil, nil, err
	}

	log.Info("segment persistent to storage", "segment", seg, "volume", volName,
		"blocks", stats.Blocks,
		"size", stats.TotalBytes)

	return entries, stats, nil
}
